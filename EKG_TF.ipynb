{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a76d978-8acd-4e05-a412-936db6b491d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from fitparse import FitFile\n",
    "import neurokit2 as nk\n",
    "#import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e472d61e-0998-4817-b970-3ae921dc7828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990832a0-f459-48b1-bbf1-42564c908a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitEKGAnalyzerWithML(object):\n",
    "    \"\"\"\n",
    "    A class to analyze EKG data from FIT files using pre-trained ML models\n",
    "    to classify heartbeats and detect abnormalities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with a FIT file path.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        file_path : str\n",
    "            Path to the FIT file\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.raw_data = None\n",
    "        self.ecg_signal = None\n",
    "        self.sampling_rate = None\n",
    "        self.r_peaks = None\n",
    "        self.heartbeats = None\n",
    "        self.beat_classifications = None\n",
    "        self.metrics = {}\n",
    "        \n",
    "        # ML model attributes\n",
    "        self.model = None\n",
    "        self.model_sampling_rate = None\n",
    "        self.beat_length = None\n",
    "        self.class_mapping = None\n",
    "        \n",
    "    def load_fit_file(self):\n",
    "        \"\"\"Load and parse the FIT file\"\"\"\n",
    "        try:\n",
    "            fit_file = FitFile(self.file_path)\n",
    "            \n",
    "            # Extract EKG data - field names may vary by device\n",
    "            ecg_data = []\n",
    "            timestamps = []\n",
    "            \n",
    "            for record in fit_file.get_messages('record'):\n",
    "                # Look for ECG data fields\n",
    "                for field in record:\n",
    "                    if 'ecg' in field.name.lower() or 'ekg' in field.name.lower():\n",
    "                        ecg_data.append(field.value)\n",
    "                    if field.name == 'timestamp':\n",
    "                        timestamps.append(field.value)\n",
    "            \n",
    "            # If no explicit ECG data is found, try to use other fields\n",
    "            if not ecg_data:\n",
    "                for record in fit_file.get_messages('record'):\n",
    "                    # Some devices store ECG under different names\n",
    "                    for field in record:\n",
    "                        if field.name in ['heart_rate_raw', 'heart_waveform']:\n",
    "                            ecg_data.append(field.value)\n",
    "                        if field.name == 'timestamp':\n",
    "                            timestamps.append(field.value)\n",
    "            \n",
    "            if not ecg_data:\n",
    "                raise ValueError(\"No ECG/EKG data found in the FIT file\")\n",
    "                \n",
    "            # Estimate sampling rate from timestamps if available\n",
    "            if len(timestamps) > 1:\n",
    "                time_diff = (timestamps[-1] - timestamps[0]).total_seconds()\n",
    "                self.sampling_rate = len(ecg_data) / time_diff\n",
    "            else:\n",
    "                # Default to a common ECG sampling rate if can't be determined\n",
    "                self.sampling_rate = 250  # Hz\n",
    "            \n",
    "            self.raw_data = pd.DataFrame({\n",
    "                'timestamp': timestamps if len(timestamps) == len(ecg_data) else range(len(ecg_data)),\n",
    "                'ecg': ecg_data\n",
    "            })\n",
    "            \n",
    "            self.ecg_signal = np.array(ecg_data)\n",
    "            \n",
    "            print(f\"Loaded ECG data with {len(ecg_data)} samples at {self.sampling_rate:.2f} Hz\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading FIT file: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def preprocess_ecg(self):\n",
    "        \"\"\"Preprocess the ECG signal by removing noise and baseline wander\"\"\"\n",
    "        if self.ecg_signal is None:\n",
    "            print(\"No ECG data loaded. Please load a FIT file first.\")\n",
    "            return False\n",
    "        \n",
    "        # Apply bandpass filter to remove noise\n",
    "        # ECG typically has frequency components between 0.5 and 40 Hz\n",
    "        self.ecg_signal = nk.ecg_clean(self.ecg_signal, sampling_rate=self.sampling_rate)\n",
    "        return True\n",
    "    \n",
    "    def detect_r_peaks(self):\n",
    "        \"\"\"Detect R-peaks in the ECG signal\"\"\"\n",
    "        if self.ecg_signal is None:\n",
    "            print(\"No ECG data loaded. Please load a FIT file first.\")\n",
    "            return False\n",
    "        \n",
    "        # Use neurokit2 for R-peak detection\n",
    "        _, info = nk.ecg_peaks(self.ecg_signal, sampling_rate=self.sampling_rate)\n",
    "        self.r_peaks = info['ECG_R_Peaks']\n",
    "        \n",
    "        print(f\"Detected {len(self.r_peaks)} R-peaks\")\n",
    "        return True\n",
    "    \n",
    "    def segment_heartbeats(self):\n",
    "        \"\"\"Segment the ECG signal into individual heartbeats\"\"\"\n",
    "        if self.r_peaks is None:\n",
    "            print(\"No R-peaks detected. Please run detect_r_peaks first.\")\n",
    "            return False\n",
    "        \n",
    "        # Segment heartbeats around R-peaks\n",
    "        # Typical heartbeat is ~200ms before R-peak and ~400ms after\n",
    "        before = int(0.2 * self.sampling_rate)\n",
    "        after = int(0.4 * self.sampling_rate)\n",
    "        \n",
    "        self.heartbeats = []\n",
    "        self.heartbeat_indices = []  # Store indices for later reference\n",
    "        \n",
    "        for r_peak in self.r_peaks:\n",
    "            if r_peak - before >= 0 and r_peak + after < len(self.ecg_signal):\n",
    "                beat = self.ecg_signal[r_peak - before : r_peak + after]\n",
    "                self.heartbeats.append(beat)\n",
    "                self.heartbeat_indices.append((r_peak - before, r_peak + after))\n",
    "        \n",
    "        print(f\"Segmented {len(self.heartbeats)} heartbeats\")\n",
    "        return True\n",
    "    \n",
    "    def load_model(self, model_path='ecg_model', scaler_path=None):\n",
    "        \"\"\"\n",
    "        Load a pre-trained ECG classification model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_path : str\n",
    "            Path to the saved model\n",
    "        scaler_path : str, optional\n",
    "            Path to the saved scaler for feature normalization\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load the TensorFlow/Keras model\n",
    "            self.model = tf.keras.models.load_model(model_path)\n",
    "            \n",
    "            # Load the scaler if provided\n",
    "            self.scaler = None\n",
    "            if scaler_path and os.path.exists(scaler_path):\n",
    "                with open(scaler_path, 'rb') as f:\n",
    "                    self.scaler = pickle.load(f)\n",
    "            \n",
    "            # Get model configuration\n",
    "            # This assumes the model expects a specific input shape\n",
    "            input_shape = self.model.layers[0].input_shape\n",
    "            \n",
    "            if isinstance(input_shape, list):\n",
    "                # If model has multiple inputs\n",
    "                self.beat_length = input_shape[0][1]\n",
    "            else:\n",
    "                # Single input model\n",
    "                self.beat_length = input_shape[1]\n",
    "            \n",
    "            # Default to 250Hz if model was trained on that rate\n",
    "            # This is common for PhysioNet models\n",
    "            self.model_sampling_rate = 250\n",
    "            \n",
    "            # Define class mapping based on PhysioNet 2020 Challenge\n",
    "            self.class_mapping = {\n",
    "                0: 'Normal',\n",
    "                1: 'AF',       # Atrial Fibrillation\n",
    "                2: 'IAVB',     # First-degree AV block\n",
    "                3: 'LBBB',     # Left bundle branch block\n",
    "                4: 'RBBB',     # Right bundle branch block\n",
    "                5: 'PAC',      # Premature atrial contraction\n",
    "                6: 'PVC',      # Premature ventricular contraction\n",
    "                7: 'STD',      # ST-segment depression\n",
    "                8: 'STE',      # ST-segment elevation\n",
    "            }\n",
    "            \n",
    "            print(f\"Loaded model expecting input length: {self.beat_length}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            print(\"Since the model couldn't be loaded, will use simplified classification.\")\n",
    "            return False\n",
    "    \n",
    "    def preprocess_beat_for_model(self, beat):\n",
    "        \"\"\"\n",
    "        Preprocess a single heartbeat for model input\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        beat : numpy.ndarray\n",
    "            Raw heartbeat signal\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Preprocessed beat ready for model input\n",
    "        \"\"\"\n",
    "        # Resample to expected input length\n",
    "        if len(beat) != self.beat_length:\n",
    "            beat = signal.resample(beat, self.beat_length)\n",
    "        \n",
    "        # Normalize\n",
    "        beat = (beat - np.mean(beat)) / (np.std(beat) + 1e-6)  # Add small epsilon to avoid div by zero\n",
    "        \n",
    "        # Apply scaler if available\n",
    "        if self.scaler is not None:\n",
    "            beat = self.scaler.transform(beat.reshape(1, -1)).reshape(-1)\n",
    "        \n",
    "        return beat\n",
    "    \n",
    "    def extract_beat_features(self, beat):\n",
    "        \"\"\"\n",
    "        Extract additional features from a heartbeat for models that need them\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        beat : numpy.ndarray\n",
    "            Preprocessed heartbeat signal\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Feature vector\n",
    "        \"\"\"\n",
    "        # Example features (customize based on your model's requirements)\n",
    "        features = []\n",
    "        \n",
    "        # Statistical features\n",
    "        features.append(np.mean(beat))\n",
    "        features.append(np.std(beat))\n",
    "        features.append(np.max(beat))\n",
    "        features.append(np.min(beat))\n",
    "        \n",
    "        # Spectral features\n",
    "        freqs, psd = signal.welch(beat, fs=self.model_sampling_rate)\n",
    "        \n",
    "        # Get power in relevant frequency bands\n",
    "        # P wave: 0.5-3 Hz\n",
    "        # QRS complex: 3-40 Hz\n",
    "        # T wave: 0.5-7 Hz\n",
    "        p_power = np.sum(psd[(freqs >= 0.5) & (freqs <= 3)])\n",
    "        qrs_power = np.sum(psd[(freqs >= 3) & (freqs <= 40)])\n",
    "        t_power = np.sum(psd[(freqs >= 0.5) & (freqs <= 7)])\n",
    "        \n",
    "        features.extend([p_power, qrs_power, t_power])\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def classify_beats_with_ml(self):\n",
    "        \"\"\"Classify beats using the pre-trained ML model\"\"\"\n",
    "        if self.heartbeats is None or len(self.heartbeats) == 0:\n",
    "            print(\"No heartbeats segmented. Please run segment_heartbeats first.\")\n",
    "            return False\n",
    "        \n",
    "        if self.model is None:\n",
    "            print(\"No model loaded. Using simplified classification method instead.\")\n",
    "            return self.classify_beats_simple()\n",
    "        \n",
    "        # Preprocess beats to match model input requirements\n",
    "        X = []\n",
    "        for beat in self.heartbeats:\n",
    "            processed_beat = self.preprocess_beat_for_model(beat)\n",
    "            X.append(processed_beat)\n",
    "        \n",
    "        # Convert to appropriate array format for model\n",
    "        # Adjust shape based on your model's expected input\n",
    "        X = np.array(X).reshape(-1, self.beat_length, 1)\n",
    "        \n",
    "        # Make predictions\n",
    "        try:\n",
    "            predictions = self.model.predict(X)\n",
    "            \n",
    "            # If model outputs probabilities for multiple classes\n",
    "            if predictions.shape[1] > 1:\n",
    "                # Get the class with highest probability\n",
    "                predicted_classes = np.argmax(predictions, axis=1)\n",
    "            else:\n",
    "                # Binary classification\n",
    "                predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "            \n",
    "            # Map to class names\n",
    "            self.beat_classifications = [\n",
    "                self.class_mapping.get(pred_class, 'Unknown') \n",
    "                for pred_class in predicted_classes\n",
    "            ]\n",
    "            \n",
    "            # Calculate statistics\n",
    "            self.calculate_classification_stats()\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error making predictions: {e}\")\n",
    "            print(\"Falling back to simplified classification method.\")\n",
    "            return self.classify_beats_simple()\n",
    "    \n",
    "    def classify_beats_simple(self):\n",
    "        \"\"\"\n",
    "        Simplified beat classification when no model is available\n",
    "        This is a backup method\n",
    "        \"\"\"\n",
    "        if self.heartbeats is None:\n",
    "            print(\"No heartbeats segmented. Please run segment_heartbeats first.\")\n",
    "            return False\n",
    "        \n",
    "        # Calculate RR intervals\n",
    "        rr_intervals = np.diff(self.r_peaks) / self.sampling_rate * 1000  # in ms\n",
    "        \n",
    "        # Simple classification\n",
    "        classifications = []\n",
    "        \n",
    "        # First beat\n",
    "        classifications.append('Normal')\n",
    "        \n",
    "        # For remaining beats\n",
    "        for i in range(1, len(self.heartbeats)):\n",
    "            beat = self.heartbeats[i]\n",
    "            rr = rr_intervals[i-1] if i-1 < len(rr_intervals) else None\n",
    "            \n",
    "            # Simple rules based on RR interval and beat morphology\n",
    "            if rr is not None and rr < 600:  # Short RR interval\n",
    "                if np.max(beat) - np.min(beat) > 1.5 * np.mean([b.max() - b.min() for b in self.heartbeats]):\n",
    "                    classifications.append('PVC')  # Premature Ventricular Contraction\n",
    "                else:\n",
    "                    classifications.append('PAC')  # Premature Atrial Contraction\n",
    "            else:\n",
    "                classifications.append('Normal')\n",
    "        \n",
    "        self.beat_classifications = classifications\n",
    "        \n",
    "        # Calculate statistics\n",
    "        self.calculate_classification_stats()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def calculate_classification_stats(self):\n",
    "        \"\"\"Calculate statistics for beat classifications\"\"\"\n",
    "        if self.beat_classifications is None:\n",
    "            return\n",
    "        \n",
    "        total_beats = len(self.beat_classifications)\n",
    "        unique_classifications = set(self.beat_classifications)\n",
    "        \n",
    "        stats = {}\n",
    "        for classification in unique_classifications:\n",
    "            count = self.beat_classifications.count(classification)\n",
    "            percentage = (count / total_beats) * 100\n",
    "            stats[classification] = {\n",
    "                'count': count,\n",
    "                'percentage': percentage\n",
    "            }\n",
    "        \n",
    "        self.metrics['beat_classifications'] = stats\n",
    "        self.metrics['total_beats'] = total_beats\n",
    "        \n",
    "        # Calculate percentage of abnormal beats (non-Normal)\n",
    "        normal_percentage = stats.get('Normal', {'percentage': 0})['percentage']\n",
    "        self.metrics['abnormal_percentage'] = 100 - normal_percentage\n",
    "    \n",
    "    def calculate_hrv_metrics(self):\n",
    "        \"\"\"Calculate Heart Rate Variability metrics\"\"\"\n",
    "        if self.r_peaks is None:\n",
    "            print(\"No R-peaks detected. Please run detect_r_peaks first.\")\n",
    "            return False\n",
    "        \n",
    "        # Calculate RR intervals in seconds\n",
    "        rr_intervals = np.diff(self.r_peaks) / self.sampling_rate\n",
    "        \n",
    "        # Time domain HRV metrics\n",
    "        self.metrics['hrv'] = {}\n",
    "        self.metrics['hrv']['mean_hr'] = 60 / np.mean(rr_intervals)\n",
    "        self.metrics['hrv']['sdnn'] = np.std(rr_intervals) * 1000  # in ms\n",
    "        self.metrics['hrv']['rmssd'] = np.sqrt(np.mean(np.square(np.diff(rr_intervals)))) * 1000  # in ms\n",
    "        \n",
    "        # Calculate pNN50 (percentage of successive RR intervals that differ by more than 50 ms)\n",
    "        nn50 = sum(abs(np.diff(rr_intervals)) > 0.05)  # 0.05s = 50ms\n",
    "        self.metrics['hrv']['pnn50'] = (nn50 / len(rr_intervals)) * 100 if len(rr_intervals) > 0 else 0\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def run_full_analysis(self, model_path=None, scaler_path=None):\n",
    "        \"\"\"\n",
    "        Run the complete analysis pipeline\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_path : str, optional\n",
    "            Path to the pre-trained model\n",
    "        scaler_path : str, optional\n",
    "            Path to the feature scaler\n",
    "        \"\"\"\n",
    "        if not self.load_fit_file():\n",
    "            return False\n",
    "        \n",
    "        if not self.preprocess_ecg():\n",
    "            return False\n",
    "        \n",
    "        if not self.detect_r_peaks():\n",
    "            return False\n",
    "        \n",
    "        if not self.segment_heartbeats():\n",
    "            return False\n",
    "        \n",
    "        # Try to load model if path provided\n",
    "        if model_path:\n",
    "            self.load_model(model_path, scaler_path)\n",
    "        \n",
    "        # Use ML classification if model loaded, otherwise use simple method\n",
    "        if self.model:\n",
    "            if not self.classify_beats_with_ml():\n",
    "                return False\n",
    "        else:\n",
    "            if not self.classify_beats_simple():\n",
    "                return False\n",
    "        \n",
    "        if not self.calculate_hrv_metrics():\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate a report with the analysis results\"\"\"\n",
    "        if not self.metrics:\n",
    "            print(\"No analysis results available. Please run the analysis first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n===== EKG Analysis Report =====\")\n",
    "        \n",
    "        # Basic information\n",
    "        print(f\"\\nFile: {os.path.basename(self.file_path)}\")\n",
    "        print(f\"Total Duration: {len(self.ecg_signal)/self.sampling_rate:.2f} seconds\")\n",
    "        print(f\"Total Beats Analyzed: {self.metrics['total_beats']}\")\n",
    "        \n",
    "        # Beat classifications\n",
    "        print(\"\\nBeat Classifications:\")\n",
    "        for classification, data in self.metrics['beat_classifications'].items():\n",
    "            print(f\"  {classification}: {data['count']} beats ({data['percentage']:.2f}%)\")\n",
    "        \n",
    "        print(f\"\\nAbnormal Beats: {self.metrics['abnormal_percentage']:.2f}%\")\n",
    "        \n",
    "        # HRV metrics\n",
    "        print(\"\\nHeart Rate Variability Metrics:\")\n",
    "        print(f\"  Mean Heart Rate: {self.metrics['hrv']['mean_hr']:.2f} bpm\")\n",
    "        print(f\"  SDNN: {self.metrics['hrv']['sdnn']:.2f} ms\")\n",
    "        print(f\"  RMSSD: {self.metrics['hrv']['rmssd']:.2f} ms\")\n",
    "        print(f\"  pNN50: {self.metrics['hrv']['pnn50']:.2f}%\")\n",
    "    \n",
    "    def plot_ecg_with_classifications(self, save_path=None):\n",
    "        \"\"\"Plot the ECG signal with beat classifications\"\"\"\n",
    "        if self.ecg_signal is None or self.r_peaks is None or self.beat_classifications is None:\n",
    "            print(\"Missing data for plotting. Please run the full analysis first.\")\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # Plot the ECG signal\n",
    "        time = np.arange(len(self.ecg_signal)) / self.sampling_rate\n",
    "        plt.plot(time, self.ecg_signal, 'b-', alpha=0.5, label='ECG Signal')\n",
    "        \n",
    "        # Plot R-peaks with classification colors\n",
    "        colors = {\n",
    "            'Normal': 'green',\n",
    "            'PVC': 'red',\n",
    "            'PAC': 'orange',\n",
    "            'LBBB': 'purple',\n",
    "            'RBBB': 'brown',\n",
    "            'AF': 'magenta',\n",
    "            'IAVB': 'cyan',\n",
    "            'STD': 'yellow',\n",
    "            'STE': 'pink',\n",
    "            'Unknown': 'gray'\n",
    "        }\n",
    "        \n",
    "        for i, r_peak in enumerate(self.r_peaks):\n",
    "            if i < len(self.beat_classifications):\n",
    "                beat_class = self.beat_classifications[i]\n",
    "                color = colors.get(beat_class, 'blue')\n",
    "                plt.plot(r_peak/self.sampling_rate, self.ecg_signal[r_peak], 'o', \n",
    "                         color=color, markersize=8)\n",
    "        \n",
    "        # Create legend\n",
    "        legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                          markerfacecolor=color, markersize=8, label=classification)\n",
    "                          for classification, color in colors.items() \n",
    "                          if classification in self.beat_classifications]\n",
    "        \n",
    "        plt.legend(handles=legend_elements, loc='upper right')\n",
    "        plt.title('ECG Signal with Beat Classifications')\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Plot saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f18a899c-176c-48cd-8273-51409c5ceb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = FitEKGAnalyzerWithML('/Users/emccullough/Downloads/Activity_on_20240813_052850_by_Etienne_5010176_94deb87f66d7_FITFILE.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c437345b-c1d5-4205-b2ec-f6b022ca618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EKG Analysis with ML-based Classification\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to download/setup a pre-trained model? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function would normally download a model from PhysioNet.\n",
      "For demonstration purposes, we'll create a placeholder model structure.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 125\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalysis failed. Please check the file and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[15], line 97\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_model\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 97\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m download_physionet_model()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter path to existing model (leave blank to use simple classification): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 36\u001b[0m, in \u001b[0;36mdownload_physionet_model\u001b[0;34m(output_dir)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor demonstration purposes, we\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mll create a placeholder model structure.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# In a real implementation, you would download the model files\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# url = \"https://physionet.org/files/challenge-2020/1.0.1/models/team_name_model.zip\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Instead, let's create a simple Keras model as a placeholder\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# This is just for demonstration - use a real pre-trained model in practice\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     37\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m250\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m     38\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv1D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     39\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling1D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     40\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv1D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     41\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling1D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     42\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[1;32m     43\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     44\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m9\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 9 classes from PhysioNet 2020\u001b[39;00m\n\u001b[1;32m     45\u001b[0m ])\n\u001b[1;32m     47\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     48\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     49\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     50\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to download and prepare a PhysioNet model\n",
    "def download_physionet_model(output_dir='ecg_model'):\n",
    "    \"\"\"\n",
    "    Download and prepare a pre-trained PhysioNet ECG model\n",
    "    \n",
    "    This is a simplified example that shows how to access a model\n",
    "    from PhysioNet's 2020 Challenge. In practice, you would need\n",
    "    to adapt this to the specific model you want to use.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    output_dir : str\n",
    "        Directory to save the model\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    import zipfile\n",
    "    import io\n",
    "    import json\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    print(\"This function would normally download a model from PhysioNet.\")\n",
    "    print(\"For demonstration purposes, we'll create a placeholder model structure.\")\n",
    "    \n",
    "    # In a real implementation, you would download the model files\n",
    "    # Example:\n",
    "    # url = \"https://physionet.org/files/challenge-2020/1.0.1/models/team_name_model.zip\"\n",
    "    # response = requests.get(url)\n",
    "    # with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "    #     z.extractall(output_dir)\n",
    "    \n",
    "    # Instead, let's create a simple Keras model as a placeholder\n",
    "    # This is just for demonstration - use a real pre-trained model in practice\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(250, 1)),\n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=5, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(9, activation='softmax')  # 9 classes from PhysioNet 2020\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(output_dir)\n",
    "    \n",
    "    # Save model metadata\n",
    "    metadata = {\n",
    "        'name': 'PhysioNet_2020_ECG_Classifier',\n",
    "        'description': 'Placeholder model for ECG classification',\n",
    "        'input_shape': [250, 1],\n",
    "        'output_shape': 9,\n",
    "        'classes': {\n",
    "            '0': 'Normal',\n",
    "            '1': 'AF',\n",
    "            '2': 'IAVB',\n",
    "            '3': 'LBBB',\n",
    "            '4': 'RBBB',\n",
    "            '5': 'PAC',\n",
    "            '6': 'PVC',\n",
    "            '7': 'STD',\n",
    "            '8': 'STE'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    print(f\"Created placeholder model in {output_dir}\")\n",
    "    print(\"Note: This is not a trained model and won't make useful predictions.\")\n",
    "    print(\"In practice, you should download a real pre-trained model.\")\n",
    "    \n",
    "    return os.path.abspath(output_dir)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to demonstrate the EKG Analyzer with ML model\n",
    "    \"\"\"\n",
    "    print(\"EKG Analysis with ML-based Classification\")\n",
    "    print(\"========================================\")\n",
    "    \n",
    "    # Option to download a model\n",
    "    download_model = input(\"Do you want to download/setup a pre-trained model? (y/n): \")\n",
    "    model_path = None\n",
    "    \n",
    "    if download_model.lower() == 'y':\n",
    "        model_path = download_physionet_model()\n",
    "    else:\n",
    "        model_path = input(\"Enter path to existing model (leave blank to use simple classification): \")\n",
    "        if not model_path or not os.path.exists(model_path):\n",
    "            model_path = None\n",
    "    \n",
    "    # Get file path from user\n",
    "    file_path = input(\"Enter the path to your FIT file: \")\n",
    "    \n",
    "    # Create analyzer and run analysis\n",
    "    analyzer = FitEKGAnalyzerWithML(file_path)\n",
    "    if analyzer.run_full_analysis(model_path=model_path):\n",
    "        analyzer.generate_report()\n",
    "        \n",
    "        # Ask if user wants to save a plot\n",
    "        save_plot = input(\"Do you want to save a plot of the ECG with classifications? (y/n): \")\n",
    "        if save_plot.lower() == 'y':\n",
    "            plot_path = input(\"Enter the path to save the plot (or press Enter for default): \")\n",
    "            if not plot_path:\n",
    "                plot_path = os.path.splitext(file_path)[0] + \"_ecg_analysis.png\"\n",
    "            analyzer.plot_ecg_with_classifications(save_path=plot_path)\n",
    "        else:\n",
    "            analyzer.plot_ecg_with_classifications()\n",
    "    else:\n",
    "        print(\"Analysis failed. Please check the file and try again.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7086f-ece8-4d14-9370-1484092aeff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
